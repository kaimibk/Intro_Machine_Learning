{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Preamble\" data-toc-modified-id=\"Preamble-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Preamble</a></span></li><li><span><a href=\"#Executing-a-simple-perceptron\" data-toc-modified-id=\"Executing-a-simple-perceptron-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Executing a simple perceptron</a></span></li><li><span><a href=\"#Visualizing-the-Perceptron\" data-toc-modified-id=\"Visualizing-the-Perceptron-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Visualizing the Perceptron</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preamble"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I present an example of the Perceptron learning algorithm. Specifically, I will perform binary classification on points--on a cartesian plane--generated around some true line. In this example, we will say points above the true line have a \"label\" of _1_, while those below are _-1_. We will initially analyze input vectors sampled from a uniform distribution, however in later tests we will inspect those generated from other distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define here an activation function which takes the neuron internal \"communication\" and converts it into a binary output; whether or not the neuron will fire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sign(n):\n",
    "    if n >= 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we define the \"true\" line seperating the data points. Below is a line of the form $y=m x + b$, where the particular slope, _m_, and intercept _b_ were chose ad hoc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    return 0.3 * x - 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we define the learning algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Perceptron:\n",
    "\n",
    "    def __init__(self, lr):\n",
    "        self.weights = np.random.uniform(-1,1,3)\n",
    "        self.lr = lr\n",
    "    \n",
    "    def guess_func(self, inputs):\n",
    "        Sum = 0\n",
    "        \n",
    "        for i in range(len(self.weights)):\n",
    "            Sum += np.array(inputs[i]) * np.array(self.weights[i])\n",
    "        \n",
    "        return sign(Sum)\n",
    "    \n",
    "    def train(self, inputs, target):\n",
    "        guess = self.guess_func(inputs)\n",
    "    \n",
    "        error = target - guess\n",
    "        \n",
    "        for i in range(len(self.weights)):\n",
    "            self.weights[i] += error*inputs[i]*self.lr\n",
    "    \n",
    "#     def guess_y(self, x):\n",
    "#         w0, w1, w2 = self.weights\n",
    "        \n",
    "#         return (-w2 / w1) - (w0/w1)*x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Various Tests with Our Learning Machine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Executing a simple perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I will start by generating N=100 input vectors, _X_, with dimensions (3, 100). Which can be understood as coordiantes (x,y) and a bias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "N = 100\n",
    "X = np.stack([\n",
    "        np.random.uniform(-1, 1, size=N), \n",
    "        np.random.uniform(-1, 1, size=N), \n",
    "        np.ones(N)], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Executing the learning algorithm for given number of epochs and a learning rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def main(n_epoch, lr):\n",
    "    neuron = Perceptron(lr=lr)\n",
    "    for epoch in range(1, n_epoch+1):\n",
    "        correct = []\n",
    "        for index, point in enumerate(X):\n",
    "            target = (lambda x: 1 if x > f(x) else -1)(point[0])\n",
    "\n",
    "            guess = neuron.guess_func(point)\n",
    "\n",
    "            neuron.train(point, target)\n",
    "                        \n",
    "            if guess == target:\n",
    "                correct.append(index)\n",
    "        print(\"Epoch {}: {} points were correctly classified\".format(epoch, \n",
    "                                                                     len(correct)))\n",
    "        \n",
    "        ## if all of the points are correctly classifed, stop the algorithm.\n",
    "        if len(correct) == 100:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 92 points were correctly classified\n",
      "Epoch 2: 98 points were correctly classified\n",
      "Epoch 3: 98 points were correctly classified\n",
      "Epoch 4: 98 points were correctly classified\n",
      "Epoch 5: 96 points were correctly classified\n",
      "Epoch 6: 98 points were correctly classified\n",
      "Epoch 7: 98 points were correctly classified\n",
      "Epoch 8: 100 points were correctly classified\n"
     ]
    }
   ],
   "source": [
    "main(n_epoch=10, lr=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see above, the  algorithm quickly classifies the input vectors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing the Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:UHenv]",
   "language": "python",
   "name": "conda-env-UHenv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
